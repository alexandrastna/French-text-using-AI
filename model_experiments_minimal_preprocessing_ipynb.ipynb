{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandrastna/French-text-using-AI/blob/main/model_experiments_minimal_preprocessing_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict the difficulty of French text using AI\n",
        "\n",
        "Initial models with minimal data preprocessing and no hyper-parameter tuning."
      ],
      "metadata": {
        "id": "BH-HwdJz8o_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing ###"
      ],
      "metadata": {
        "id": "JpsuqpdL80RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "qX43atxh8EvH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j_FylzO-gOFS"
      },
      "outputs": [],
      "source": [
        "#Load the data\n",
        "\n",
        "df_training_data = pd.read_csv('https://raw.githubusercontent.com/alexandrastna/French-text-using-AI/main/training_data.csv')\n",
        "\n",
        "df_sample_submission = pd.read_csv('https://raw.githubusercontent.com/alexandrastna/French-text-using-AI/main/sample_submission.csv')\n",
        "\n",
        "df_unlabelled_test_data = pd.read_csv('https://raw.githubusercontent.com/alexandrastna/French-text-using-AI/main/unlabelled_test_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data exploration:"
      ],
      "metadata": {
        "id": "lfqjrLuH-rgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_training_data.head()\n",
        "df_training_data.describe()\n",
        "df_training_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2dsEwvg-iiQ",
        "outputId": "d000f0af-b9c2-4f88-827e-6a5e2f9e36e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4800 entries, 0 to 4799\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          4800 non-null   int64 \n",
            " 1   sentence    4800 non-null   object\n",
            " 2   difficulty  4800 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 112.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning:"
      ],
      "metadata": {
        "id": "kVNTPenZ-wQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df_training_data.isnull().sum())\n",
        "\n",
        "# If any, decide on the strategy; for example, dropping:\n",
        "df_training_data.dropna(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGg8Z-Qk-xbd",
        "outputId": "86dd40ad-4209-4e1a-e232-0acf55f65b0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id            0\n",
            "sentence      0\n",
            "difficulty    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing:"
      ],
      "metadata": {
        "id": "DPcKYBK_Eiep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "df_training_data['difficulty_encoded'] = label_encoder.fit_transform(df_training_data['difficulty'])\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_training_data['sentence']\n",
        "y = df_training_data['difficulty_encoded']\n",
        "\n",
        "# Vectorize the sentences\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "xHCtxISTEwVj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training ###"
      ],
      "metadata": {
        "id": "SDKCNTkqBeKv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression ###"
      ],
      "metadata": {
        "id": "aVviNQyuBomh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence if necessary\n",
        "\n",
        "# Train the model\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model\n",
        "y_pred_val_log = logreg.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_val, y_pred_val_log)\n",
        "precision = precision_score(y_val, y_pred_val_log, average='weighted')  # 'weighted' accounts for label imbalance\n",
        "recall = recall_score(y_val, y_pred_val_log, average='weighted')\n",
        "f1 = f1_score(y_val, y_pred_val_log, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Logistic Regression Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "\n",
        "# Print the classification report and confusion matrix\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_val_log))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_val_log))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Lz7hNlFbO_",
        "outputId": "cea19fb5-a620-47b1-e369-77da987e07de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.44895833333333335\n",
            "Precision: 0.4409901928071059\n",
            "Recall: 0.44895833333333335\n",
            "F1-Score: 0.4400315184878664\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.64      0.56       166\n",
            "           1       0.34      0.30      0.32       158\n",
            "           2       0.41      0.27      0.33       166\n",
            "           3       0.44      0.41      0.43       153\n",
            "           4       0.45      0.48      0.47       152\n",
            "           5       0.51      0.58      0.54       165\n",
            "\n",
            "    accuracy                           0.45       960\n",
            "   macro avg       0.44      0.45      0.44       960\n",
            "weighted avg       0.44      0.45      0.44       960\n",
            "\n",
            "Confusion Matrix:\n",
            " [[107  32  12  10   3   2]\n",
            " [ 55  48  27   9   9  10]\n",
            " [ 34  50  45  10   7  20]\n",
            " [  9   5  10  63  39  27]\n",
            " [  8   3   7  27  73  34]\n",
            " [  5   3   9  23  30  95]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machines (SVM) ###"
      ],
      "metadata": {
        "id": "TIQfLllTDNcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm = SVC(kernel='linear')  # The kernel can be 'linear', 'poly', 'rbf', 'sigmoid', etc.\n",
        "\n",
        "# Train the model\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model\n",
        "y_pred_val_svm = svm.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_svm = accuracy_score(y_val, y_pred_val_svm)\n",
        "precision_svm = precision_score(y_val, y_pred_val_svm, average='weighted')  # 'weighted' accounts for label imbalance\n",
        "recall_svm = recall_score(y_val, y_pred_val_svm, average='weighted')\n",
        "f1_svm = f1_score(y_val, y_pred_val_svm, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"SVM Accuracy: {accuracy_svm}\")\n",
        "print(f\"Precision: {precision_svm}\")\n",
        "print(f\"Recall: {recall_svm}\")\n",
        "print(f\"F1-Score: {f1_svm}\")\n",
        "\n",
        "# Print the classification report and confusion matrix\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_val_svm))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_val_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-OxmdxIDPoo",
        "outputId": "c38b689e-58d1-48f0-be42-e663c07ed284"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.45416666666666666\n",
            "Precision: 0.4494598616869399\n",
            "Recall: 0.45416666666666666\n",
            "F1-Score: 0.44985008847754787\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.64      0.58       166\n",
            "           1       0.34      0.35      0.35       158\n",
            "           2       0.40      0.31      0.35       166\n",
            "           3       0.44      0.43      0.44       153\n",
            "           4       0.44      0.45      0.44       152\n",
            "           5       0.54      0.55      0.54       165\n",
            "\n",
            "    accuracy                           0.45       960\n",
            "   macro avg       0.45      0.45      0.45       960\n",
            "weighted avg       0.45      0.45      0.45       960\n",
            "\n",
            "Confusion Matrix:\n",
            " [[106  38   9   7   6   0]\n",
            " [ 51  55  37   7   5   3]\n",
            " [ 28  55  51  11   6  15]\n",
            " [  7   6  12  66  38  24]\n",
            " [  6   3  11  30  68  34]\n",
            " [  3   3   8  28  33  90]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forests ###"
      ],
      "metadata": {
        "id": "XBIGqbw1CXZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model\n",
        "y_pred_val_rf = rf.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_rf = accuracy_score(y_val, y_pred_val_rf)\n",
        "precision_rf = precision_score(y_val, y_pred_val_rf, average='weighted')  # 'weighted' accounts for label imbalance\n",
        "recall_rf = recall_score(y_val, y_pred_val_rf, average='weighted')\n",
        "f1_rf = f1_score(y_val, y_pred_val_rf, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf}\")\n",
        "print(f\"Precision: {precision_rf}\")\n",
        "print(f\"Recall: {recall_rf}\")\n",
        "print(f\"F1-Score: {f1_rf}\")\n",
        "\n",
        "# Print the classification report and confusion matrix\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_val_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_val_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg8D3nvyCjmD",
        "outputId": "c34f83ee-f46c-455e-c9ea-3b6baa750eff"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.40520833333333334\n",
            "Precision: 0.4019891511153694\n",
            "Recall: 0.40520833333333334\n",
            "F1-Score: 0.3903587582946592\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.78      0.57       166\n",
            "           1       0.33      0.27      0.30       158\n",
            "           2       0.36      0.23      0.29       166\n",
            "           3       0.37      0.39      0.38       153\n",
            "           4       0.37      0.38      0.37       152\n",
            "           5       0.53      0.37      0.44       165\n",
            "\n",
            "    accuracy                           0.41       960\n",
            "   macro avg       0.40      0.40      0.39       960\n",
            "weighted avg       0.40      0.41      0.39       960\n",
            "\n",
            "Confusion Matrix:\n",
            " [[130  18   7   8   2   1]\n",
            " [ 77  43  26   5   4   3]\n",
            " [ 45  46  39  15  10  11]\n",
            " [ 15   8  18  59  39  14]\n",
            " [ 11   5   8  46  57  25]\n",
            " [ 12  11   9  28  44  61]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Trees ###"
      ],
      "metadata": {
        "id": "MHE4Mj6rC9yD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the Decision Tree model\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model\n",
        "y_pred_val_dt = dt.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_dt = accuracy_score(y_val, y_pred_val_dt)\n",
        "precision_dt = precision_score(y_val, y_pred_val_dt, average='weighted')  # 'weighted' accounts for label imbalance\n",
        "recall_dt = recall_score(y_val, y_pred_val_dt, average='weighted')\n",
        "f1_dt = f1_score(y_val, y_pred_val_dt, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt}\")\n",
        "print(f\"Precision: {precision_dt}\")\n",
        "print(f\"Recall: {recall_dt}\")\n",
        "print(f\"F1-Score: {f1_dt}\")\n",
        "\n",
        "# Print the classification report and confusion matrix\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_val_dt))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_val_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dLssih_C_I-",
        "outputId": "cb8c96cf-36e5-45a8-e802-5674f0dd4bf1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Accuracy: 0.3260416666666667\n",
            "Precision: 0.32244918645079756\n",
            "Recall: 0.3260416666666667\n",
            "F1-Score: 0.3229336657109519\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.55      0.52       166\n",
            "           1       0.31      0.32      0.31       158\n",
            "           2       0.30      0.23      0.26       166\n",
            "           3       0.26      0.31      0.28       153\n",
            "           4       0.24      0.22      0.23       152\n",
            "           5       0.32      0.31      0.31       165\n",
            "\n",
            "    accuracy                           0.33       960\n",
            "   macro avg       0.32      0.32      0.32       960\n",
            "weighted avg       0.32      0.33      0.32       960\n",
            "\n",
            "Confusion Matrix:\n",
            " [[92 43  9 12  5  5]\n",
            " [44 50 32 14  6 12]\n",
            " [28 34 39 27 17 21]\n",
            " [11 12 14 47 39 30]\n",
            " [ 6  8 18 44 34 42]\n",
            " [ 5 13 19 37 40 51]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors (KNN) ###"
      ],
      "metadata": {
        "id": "t3fMxhM-DH52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize the KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the model\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Validate the model\n",
        "y_pred_val_knn = knn.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_knn = accuracy_score(y_val, y_pred_val_knn)\n",
        "precision_knn = precision_score(y_val, y_pred_val_knn, average='weighted')  # 'weighted' accounts for label imbalance\n",
        "recall_knn = recall_score(y_val, y_pred_val_knn, average='weighted')\n",
        "f1_knn = f1_score(y_val, y_pred_val_knn, average='weighted')\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"KNN Accuracy: {accuracy_knn}\")\n",
        "print(f\"Precision: {precision_knn}\")\n",
        "print(f\"Recall: {recall_knn}\")\n",
        "print(f\"F1-Score: {f1_knn}\")\n",
        "\n",
        "# Print the classification report and confusion matrix\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_pred_val_knn))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_val_knn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MpLl1GKDJW0",
        "outputId": "f0b7bb38-3371-4bc8-c617-ba64e9e491b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.31979166666666664\n",
            "Precision: 0.39497806995803963\n",
            "Recall: 0.31979166666666664\n",
            "F1-Score: 0.2955634512384226\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.85      0.44       166\n",
            "           1       0.21      0.26      0.23       158\n",
            "           2       0.21      0.13      0.16       166\n",
            "           3       0.47      0.23      0.31       153\n",
            "           4       0.57      0.17      0.26       152\n",
            "           5       0.63      0.25      0.36       165\n",
            "\n",
            "    accuracy                           0.32       960\n",
            "   macro avg       0.40      0.32      0.29       960\n",
            "weighted avg       0.39      0.32      0.30       960\n",
            "\n",
            "Confusion Matrix:\n",
            " [[141  18   5   0   0   2]\n",
            " [ 99  41  16   1   0   1]\n",
            " [ 87  52  22   3   1   1]\n",
            " [ 49  32  22  35  11   4]\n",
            " [ 46  25  18  20  26  17]\n",
            " [ 53  24  23  15   8  42]]\n"
          ]
        }
      ]
    }
  ]
}